{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "#from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import Sampler, BatchSampler\n",
    "from torch.nn.modules.loss import MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSampler(BatchSampler):\n",
    "    def __init__(self, batch_size, num_classes, labels):\n",
    "        self.num_classes = num_classes\n",
    "        self.N = batch_size\n",
    "        self.labels = labels\n",
    "\n",
    "    def __iter__(self):\n",
    "        num_yielded = 0\n",
    "        while num_yielded < self.labels.size()[0]:\n",
    "            batch = torch.randint(high=self.labels.size()[0], size=(self.N,)).long()\n",
    "            num_yielded += self.N\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "batch_size = 256\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./MNIST/', \n",
    "                                   train=True, \n",
    "                                   transform=transforms.ToTensor(),\n",
    "                                   download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./MNIST/', \n",
    "                                  train=False, \n",
    "                                  transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                          batch_sampler=DataSampler(batch_size=batch_size, num_classes=num_classes, labels=train_dataset.train_labels), \n",
    "                                          shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                         batch_sampler=DataSampler(batch_size=batch_size, num_classes=num_classes, labels=test_dataset.test_labels), \n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2381179cc0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = next(iter(train_loader))\n",
    "print( x[0][0].shape )\n",
    "plt.imshow(x[0][0].reshape(28, 28) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size()[0], -1)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 1024, 4, 2, 1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(True),\n",
    "            Flatten(),\n",
    "            nn.Linear(1024, 8),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeFlatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view( -1, 1024, 7, 7 )\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Linear(8, 7 * 7 * 1024),\n",
    "            nn.ReLU(),\n",
    "            DeFlatten(),\n",
    "            nn.ConvTranspose2d(1024, 512, 4),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 1, 4, stride=2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imq_kernel(X: torch.Tensor, Y: torch.Tensor, h_dim: int):\n",
    "    batch_size = X.size(0)\n",
    "\n",
    "    p2_norm_x = X.pow(2).sum(1).unsqueeze(0)\n",
    "    norms_x = X.sum(1).unsqueeze(0)\n",
    "    prods_x = torch.mm(norms_x, norms_x.t())\n",
    "    dists_x = p2_norm_x + p2_norm_x.t() - 2 * prods_x\n",
    "\n",
    "    p2_norm_y = Y.pow(2).sum(1).unsqueeze(0)\n",
    "    norms_y = X.sum(1).unsqueeze(0)\n",
    "    prods_y = torch.mm(norms_y, norms_y.t())\n",
    "    dists_y = p2_norm_y + p2_norm_y.t() - 2 * prods_y\n",
    "\n",
    "    dot_prd = torch.mm(norms_x, norms_y.t())\n",
    "    dists_c = p2_norm_x + p2_norm_y.t() - 2 * dot_prd\n",
    "\n",
    "    stats = 0\n",
    "    for scale in [.1, .2, .5, 1., 2., 5., 10.]:\n",
    "        C = 2 * h_dim * 1.0 * scale\n",
    "        res1 = C / (C + dists_x)\n",
    "        res1 += C / (C + dists_y)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            res1 = (1 - torch.eye(batch_size).cuda()) * res1\n",
    "        else:\n",
    "            res1 = (1 - torch.eye(batch_size)) * res1\n",
    "\n",
    "        res1 = res1.sum() / (batch_size - 1)\n",
    "        res2 = C / (C + dists_c)\n",
    "        res2 = res2.sum() * 2. / (batch_size)\n",
    "        stats += res1 - res2\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:31, 31.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48249.9297)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-634232becbf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mz_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-52be4a90c04f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    689\u001b[0m         return F.conv_transpose2d(\n\u001b[1;32m    690\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoder, decoder = Encoder(), Decoder()\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "opt_e = torch.optim.Adam( encoder.parameters(), lr=0.0005 )\n",
    "opt_d = torch.optim.Adam( decoder.parameters(), lr=0.0005 )\n",
    "\n",
    "mse = MSELoss()\n",
    "\n",
    "for epoch in range(50):\n",
    "    for data, target in tqdm(train_loader):\n",
    "        opt_e.zero_grad()\n",
    "        opt_d.zero_grad()\n",
    "\n",
    "        z = encoder(data)\n",
    "        x = decoder(z)\n",
    "\n",
    "        z_f = torch.randn(data.size()[0], 8)\n",
    "\n",
    "        mmd_loss = imq_kernel(z, z_f, h_dim=8)\n",
    "        mmd_loss = mmd_loss.mean()\n",
    "\n",
    "        loss = mse(data, x) - mmd_loss\n",
    "        loss.backward()\n",
    "\n",
    "        opt_e.step()\n",
    "        opt_d.step()\n",
    "        \n",
    "        print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
